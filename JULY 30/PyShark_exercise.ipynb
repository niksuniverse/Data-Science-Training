{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PySpark Assignment – Product Sales Analysis\n",
        "\n",
        "(Intermediate)\n",
        "Part 1: Environment Setup\n",
        "1. Install Spark + Java in Google Colab.\n",
        "2. Initialize Spark with app name \"ProductSalesAnalysis\" ."
      ],
      "metadata": {
        "id": "0lz0NiscMn7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark=SparkSession.builder.appName('ProductSalesAnalysis').getOrCreate()"
      ],
      "metadata": {
        "id": "aJI5bM6OLMKT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Load Sales Data from CSV\n",
        "\n",
        "Create and load the following CSV as sales.csv :\n",
        "\n",
        "OrderID,Product,Category,Quantity,UnitPrice,Region\n",
        "\n",
        "1001,Mobile,Electronics,2,15000,North\n",
        "\n",
        "1002,Laptop,Electronics,1,55000,South\n",
        "\n",
        "1003,T-Shirt,Apparel,3,500,East\n",
        "\n",
        "1004,Jeans,Apparel,2,1200,North\n",
        "\n",
        "1005,TV,Electronics,1,40000,West\n",
        "\n",
        "1006,Shoes,Footwear,4,2000,South\n",
        "\n",
        "1007,Watch,Accessories,2,3000,East\n",
        "\n",
        "1008,Headphones,Electronics,3,2500,North\n",
        "\n",
        "Task:\n",
        "Read the file into a PySpark DataFrame with header and inferred schema.\n",
        "Print schema and show top 5 rows."
      ],
      "metadata": {
        "id": "WAzz1DpcMuZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWFsh9kMLXc8",
        "outputId": "2d10d26e-f77f-4eb8-bc67-94444af806a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the correct CSV content\n",
        "csv_data = \"\"\"OrderID,Product,Category,Quantity,UnitPrice,Region\n",
        "1001,Mobile,Electronics,2,15000,North\n",
        "1002,Laptop,Electronics,1,55000,South\n",
        "1003,T-Shirt,Apparel,3,500,East\n",
        "1004,Jeans,Apparel,2,1200,North\n",
        "1005,TV,Electronics,1,40000,West\n",
        "1006,Shoes,Footwear,4,2000,South\n",
        "1007,Watch,Accessories,2,3000,East\n",
        "1008,Headphones,Electronics,3,2500,North\"\"\"\n",
        "\n",
        "# Write it to the correct path\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/sales_data.csv\", \"w\") as f:\n",
        "    f.write(csv_data)\n",
        "\n",
        "# Reload the correct file\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/Colab Notebooks/sales_data.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40DgnDcDNnC3",
        "outputId": "aee90c97-14e9-4a3b-8273-e3e72a3b719d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- UnitPrice: integer (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            "\n",
            "+-------+----------+-----------+--------+---------+------+\n",
            "|OrderID|   Product|   Category|Quantity|UnitPrice|Region|\n",
            "+-------+----------+-----------+--------+---------+------+\n",
            "|   1001|    Mobile|Electronics|       2|    15000| North|\n",
            "|   1002|    Laptop|Electronics|       1|    55000| South|\n",
            "|   1003|   T-Shirt|    Apparel|       3|      500|  East|\n",
            "|   1004|     Jeans|    Apparel|       2|     1200| North|\n",
            "|   1005|        TV|Electronics|       1|    40000|  West|\n",
            "|   1006|     Shoes|   Footwear|       4|     2000| South|\n",
            "|   1007|     Watch|Accessories|       2|     3000|  East|\n",
            "|   1008|Headphones|Electronics|       3|     2500| North|\n",
            "+-------+----------+-----------+--------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Business Questions\n",
        "\n",
        "1. Add a new column TotalPrice = Quantity × UnitPrice\n",
        "\n"
      ],
      "metadata": {
        "id": "ZP1XVmsGM36j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"TotalPrice\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCT1JoxTMkuM",
        "outputId": "c184b46f-6d09-4bde-ced9-2ad4d2bf0ab2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "|OrderID|   Product|   Category|Quantity|UnitPrice|Region|TotalPrice|\n",
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "|   1001|    Mobile|Electronics|       2|    15000| North|     30000|\n",
            "|   1002|    Laptop|Electronics|       1|    55000| South|     55000|\n",
            "|   1003|   T-Shirt|    Apparel|       3|      500|  East|      1500|\n",
            "|   1004|     Jeans|    Apparel|       2|     1200| North|      2400|\n",
            "|   1005|        TV|Electronics|       1|    40000|  West|     40000|\n",
            "|   1006|     Shoes|   Footwear|       4|     2000| South|      8000|\n",
            "|   1007|     Watch|Accessories|       2|     3000|  East|      6000|\n",
            "|   1008|Headphones|Electronics|       3|     2500| North|      7500|\n",
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Total revenue generated across all regions.\n"
      ],
      "metadata": {
        "id": "IkNSgf5NM7hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "total_revenue = df.agg(sum(\"TotalPrice\").alias(\"TotalRevenue\"))\n",
        "total_revenue.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlylTcadMk21",
        "outputId": "6e05473f-e3e2-4e51-d6f3-23cc653ac359"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|TotalRevenue|\n",
            "+------------+\n",
            "|      150400|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Category-wise revenue sorted in descending order.\n",
        "\n"
      ],
      "metadata": {
        "id": "SPBHVb2KM7j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_revenue = df.groupBy(\"Category\").agg(sum(\"TotalPrice\").alias(\"CategoryRevenue\"))\n",
        "sorted_category_revenue = category_revenue.orderBy(col(\"CategoryRevenue\").desc())\n",
        "sorted_category_revenue.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP_-qIBDMk5o",
        "outputId": "ef4d6597-bba7-41a8-f61d-460c1c94db40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------------+\n",
            "|   Category|CategoryRevenue|\n",
            "+-----------+---------------+\n",
            "|Electronics|         132500|\n",
            "|   Footwear|           8000|\n",
            "|Accessories|           6000|\n",
            "|    Apparel|           3900|\n",
            "+-----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Region with the highest number of orders\n",
        "\n"
      ],
      "metadata": {
        "id": "7SbsIFqfM7mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region_orders = df.groupBy(\"Region\").count().orderBy(col(\"count\").desc())\n",
        "region_orders.show(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePOQHo0NMk8L",
        "outputId": "02124bb2-1774-40d6-9fdc-0678c1386693"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "| North|    3|\n",
            "+------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Average Unit Price per Category\n"
      ],
      "metadata": {
        "id": "pBd8N8r0M7pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "avg_price_category = df.groupBy(\"Category\").agg(avg(\"UnitPrice\").alias(\"AvgUnitPrice\"))\n",
        "avg_price_category.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63KJi0I7Mk-h",
        "outputId": "d2c8b2ae-f458-4070-9937-9dabca059c9c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|   Category|AvgUnitPrice|\n",
            "+-----------+------------+\n",
            "|    Apparel|       850.0|\n",
            "|Electronics|     28125.0|\n",
            "|   Footwear|      2000.0|\n",
            "|Accessories|      3000.0|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. All orders where TotalPrice is more than\n",
        "30,000"
      ],
      "metadata": {
        "id": "sY7YXe7xNDHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_value_orders = df.filter(col(\"TotalPrice\") > 30000)\n",
        "high_value_orders.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kE8S2VYMlA7",
        "outputId": "017a14aa-8ff9-4235-926b-5b3709c12e34"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "|OrderID|Product|   Category|Quantity|UnitPrice|Region|TotalPrice|\n",
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "|   1002| Laptop|Electronics|       1|    55000| South|     55000|\n",
            "|   1005|     TV|Electronics|       1|    40000|  West|     40000|\n",
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Data Transformations\n",
        "1. Create a new column HighValueOrder which is \"Yes\" if TotalPrice > 20,000,\n",
        "else \"No\" .\n"
      ],
      "metadata": {
        "id": "uenXreXoN7EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"HighValueOrder\",\n",
        "    when(col(\"TotalPrice\") > 20000, \"Yes\").otherwise(\"No\")\n",
        ")\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5gtUWq2M7Dg",
        "outputId": "85fe0220-1898-4ba5-af93-7c32e5251db3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "|OrderID|   Product|   Category|Quantity|UnitPrice|Region|TotalPrice|HighValueOrder|\n",
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "|   1001|    Mobile|Electronics|       2|    15000| North|     30000|           Yes|\n",
            "|   1002|    Laptop|Electronics|       1|    55000| South|     55000|           Yes|\n",
            "|   1003|   T-Shirt|    Apparel|       3|      500|  East|      1500|            No|\n",
            "|   1004|     Jeans|    Apparel|       2|     1200| North|      2400|            No|\n",
            "|   1005|        TV|Electronics|       1|    40000|  West|     40000|           Yes|\n",
            "|   1006|     Shoes|   Footwear|       4|     2000| South|      8000|            No|\n",
            "|   1007|     Watch|Accessories|       2|     3000|  East|      6000|            No|\n",
            "|   1008|Headphones|Electronics|       3|     2500| North|      7500|            No|\n",
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Filter and display all high-value orders in the North region.\n"
      ],
      "metadata": {
        "id": "9Nm2DNa8OIlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "north_high_value = df.filter((col(\"HighValueOrder\") == \"Yes\") & (col(\"Region\") == \"North\"))\n",
        "north_high_value.show()\n"
      ],
      "metadata": {
        "id": "9i-_6K0nMlDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Count how many high-value orders exist per region."
      ],
      "metadata": {
        "id": "bY5cnh6KOKIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_value_count = df.filter(col(\"HighValueOrder\") == \"Yes\") \\\n",
        "                     .groupBy(\"Region\") \\\n",
        "                     .count() \\\n",
        "                     .withColumnRenamed(\"count\", \"HighValueOrderCount\")\n",
        "high_value_count.show()\n"
      ],
      "metadata": {
        "id": "yyGdMLvHMlHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 5: Save Results\n",
        "Save the transformed DataFrame as a CSV file named high_value_orders.csv with\n",
        "headers."
      ],
      "metadata": {
        "id": "8lYEkiybOOP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "high_value_df = df.filter(col(\"HighValueOrder\") == \"Yes\")\n",
        "high_value_df.write.csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/high_value_orders.csv\",\n",
        "    header=True,\n",
        "    mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "Vm7EKs98MlJy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVL8e1DgMlMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXjMZMyEMlP4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}