{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb50f91-1a59-4388-91aa-ecd0243845e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_data = \"\"\"student_id,name,subject,score,grade\n",
    "1,Ankit,Math,85,A\n",
    "2,Divya,Science,92,A\n",
    "3,Rahul,English,78,B\n",
    "4,Sneha,Math,65,C\n",
    "5,Aryan,Science,55,D\n",
    "6,Isha,English,88,A\n",
    "7,Tanvi,Math,91,A\n",
    "8,Kunal,Science,72,B\n",
    "9,Megha,English,60,C\n",
    "10,Rohan,Math,40,F\n",
    "\"\"\"\n",
    "with open(\"/tmp/student_scores.csv\", \"w\") as f:\n",
    "    f.write(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53c4683-ce41-4589-b79f-f390f4e1e2c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Student Scores with Delta\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8a98cc-16a7-492d-8980-ba6f83dabe9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|current_database()|\n+------------------+\n|           default|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"SELECT current_database()\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e41aee-ea14-41e9-a7ee-b72f1b86564a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Read CSV into DataFrame\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/tmp/student_scores.csv\")\n",
    "df.show()\n",
    "\n",
    "# Step 2: Write to Delta\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/student_scores\")\n",
    "\n",
    "# Step 3: Register Delta Table\n",
    "spark.sql(\"DROP TABLE IF EXISTS student_scores\")\n",
    "spark.sql(\"CREATE TABLE student_scores USING DELTA LOCATION '/tmp/delta/student_scores'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d67eaec5-557a-4ca6-99e3-dfe73e31e47d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "BASIC QUERIES"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "spark.sql(\"SELECT name, score FROM student_scores\").show()\n",
    "\n",
    "# Task 2\n",
    "spark.sql(\"SELECT subject, COUNT(*) AS student_count FROM student_scores GROUP BY subject\").show()\n",
    "\n",
    "# Task 3\n",
    "spark.sql(\"SELECT subject, AVG(score) AS avg_score FROM student_scores GROUP BY subject\").show()\n",
    "\n",
    "# Task 4\n",
    "spark.sql(\"SELECT name, subject, score FROM student_scores WHERE score > 80\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88705820-4422-4684-8560-82ce74d2d58c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Advanced Queries"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Task 5: Highest score per subject\n",
    "df = spark.table(\"student_scores\")\n",
    "windowSpec = Window.partitionBy(\"subject\").orderBy(F.desc(\"score\"))\n",
    "\n",
    "df.withColumn(\"rank\", F.rank().over(windowSpec)) \\\n",
    "  .filter(\"rank = 1\") \\\n",
    "  .select(\"name\", \"subject\", \"score\") \\\n",
    "  .show()\n",
    "\n",
    "# Task 6\n",
    "spark.sql(\"SELECT grade, COUNT(*) AS grade_count FROM student_scores GROUP BY grade\").show()\n",
    "\n",
    "# Task 7\n",
    "spark.sql(\"SELECT name, subject, score FROM student_scores WHERE grade = 'F'\").show()\n",
    "\n",
    "# Task 8\n",
    "spark.sql(\"SELECT name, subject, score FROM student_scores WHERE score BETWEEN 60 AND 90\").show()\n",
    "\n",
    "# Task 9: Ranking within subjects\n",
    "df.withColumn(\"rank\", F.rank().over(windowSpec)) \\\n",
    "  .select(\"name\", \"subject\", \"score\", \"rank\") \\\n",
    "  .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bb9cba5-d71c-42b7-a79d-f0187902d670",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update & Delete with Delta"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Task 10: Increase score of English students by 5\n",
    "delta_table = DeltaTable.forPath(spark, \"/tmp/delta/student_scores\")\n",
    "delta_table.update(\n",
    "    condition=\"subject = 'English'\",\n",
    "    set={\"score\": \"score + 5\"}\n",
    ")\n",
    "\n",
    "# Task 11: Delete where score < 50\n",
    "delta_table.delete(\"score < 50\")\n",
    "\n",
    "# Task 12: Add pass_status column\n",
    "df = delta_table.toDF()\n",
    "df = df.withColumn(\"pass_status\", F.when(df[\"score\"] >= 50, \"PASS\").otherwise(\"FAIL\"))\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/student_scores\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4159c922-18e8-42ad-ac5e-9acf9430ad00",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Transformation & Views"
    }
   },
   "outputs": [],
   "source": [
    "# Task 13: Create temp view and run SQL\n",
    "df = spark.read.format(\"delta\").load(\"/tmp/delta/student_scores\")\n",
    "df.createOrReplaceTempView(\"temp_scores\")\n",
    "spark.sql(\"SELECT subject, AVG(score) AS avg_score FROM temp_scores GROUP BY subject\").show()\n",
    "\n",
    "# Task 14: Save as student_scores_v2 Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/student_scores_v2\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS student_scores_v2\")\n",
    "spark.sql(\"CREATE TABLE student_scores_v2 USING DELTA LOCATION '/tmp/delta/student_scores_v2'\")\n",
    "\n",
    "# Task 15: Write to Parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"/tmp/parquet/student_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "582379b0-de4c-47ac-8837-add9e7753ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "610136a9-ab2d-4b55-8488-59ea11573b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Student scores",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}