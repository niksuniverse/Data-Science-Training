{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LW9u3L6fpaz7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum as _sum, avg, when, month, year\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. Spark session (Databricks provides by default)"
      ],
      "metadata": {
        "id": "WgWtRjXspg7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = SparkSession.builder.appName(\"ETL_Unusual_Spending\").getOrCreate()\n",
        "df = spark.read.csv(\"Unusual_Spending.csv\", header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "aPAqwMQIpg1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Load raw user & expense data (assume CSV input from storage)\n",
        "# Replace paths with your ADLS/Blob or mounted location\n",
        "\n",
        "user_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/mnt/raw_data/users.csv\")\n",
        "expense_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/mnt/raw_data/expenses.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ES3xpq5Upgn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Clean data (drop nulls, cast columns, remove duplicates)\n",
        "\n",
        "user_df = user_df.dropDuplicates().na.drop()\n",
        "expense_df = (\n",
        "    expense_df\n",
        "    .dropDuplicates()\n",
        "    .na.drop()\n",
        "    .withColumn(\"amount\", col(\"amount\").cast(\"double\"))\n",
        "    .withColumn(\"date\", col(\"date\").cast(\"date\"))\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "V_3zaaP7pgaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f3kGxoJkpgTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Join user + expense data\n",
        "\n",
        "combined_df = expense_df.join(user_df, on=\"user_id\", how=\"inner\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cK6xFQFzpgM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HxIiVF03pgAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summary_df = (\n",
        "    combined_df\n",
        "    .withColumn(\"month\", month(\"date\"))\n",
        "    .withColumn(\"year\", year(\"date\"))\n",
        "    .groupBy(\"user_id\", \"user_name\", \"month\", \"year\")\n",
        "    .agg(\n",
        "        _sum(\"amount\").alias(\"total_monthly_spend\"),\n",
        "        avg(\"amount\").alias(\"avg_transaction\")\n",
        "    )\n",
        ")\n",
        "\n",
        "summary_df = summary_df.withColumn(\"savings_estimate\", col(\"total_monthly_spend\") * 0.3)\n",
        "\n",
        "user_avg_df = summary_df.groupBy(\"user_id\").agg(avg(\"total_monthly_spend\").alias(\"user_avg_spend\"))\n",
        "\n",
        "summary_df = (\n",
        "    summary_df\n",
        "    .join(user_avg_df, on=\"user_id\", how=\"left\")\n",
        "    .withColumn(\"alert_flag\",\n",
        "        when(col(\"total_monthly_spend\") > 1.5 * col(\"user_avg_spend\"), \"UNUSUAL\")\n",
        "        .otherwise(\"NORMAL\")\n",
        "    )\n",
        "    .drop(\"user_avg_spend\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "0vmfUlWFpwSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. Save results (Delta + CSV for dashboards)\n",
        "\n",
        "summary_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/processed/summary_delta\")\n",
        "\n",
        "summary_df.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(\"/mnt/processed/summary_csv\")\n",
        "\n",
        "\n",
        "# 7. Display final results (Databricks UI)\n",
        "\n",
        "display(summary_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "QQbSpedmpwQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ivm0okXvpwN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezPqB3RHpv_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}